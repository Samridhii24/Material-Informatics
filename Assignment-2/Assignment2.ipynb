{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMFbiqGKie3Ku/+jU2J4SFX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Code For Data **Cleaning**"],"metadata":{"id":"sZfCUWv-l74-"}},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import files\n","\n","# Upload the file\n","uploaded = files.upload()\n","\n","# Get the original file name\n","file_name = list(uploaded.keys())[0]\n","\n","# Read the CSV file\n","data = pd.read_csv(file_name)\n","\n","# Replace empty values in 'Test Temp (°C)' column with 25°C\n","data['Test Temp (°C)'].fillna(25, inplace=True)\n","\n","# Replace missing phases with 'Austenite + Ferrite'\n","data['Phases'].fillna('Austenite + Ferrite', inplace=True)\n","\n","# Replace missing strain rates with 0.001\n","data['Strain Rate (s⁻¹)'].fillna(0.001, inplace=True)\n","\n","# Define columns to replace with averages\n","columns_to_average = ['YS (MPa)', 'UTS (MPa)', 'Hardness (HV)', 'Dislocation Density (m⁻²)', 'Strain Hardening Exponent (n)', 'Strain Hardening Coefficient (K, MPa)', 'Grain Size (µm)', 'Elongation (%)']\n","\n","# Calculate averages for each column\n","column_averages = {}\n","for column in columns_to_average:\n","    column_averages[column] = data[column].mean()\n","\n","# Round the averages as specified\n","rounded_averages = {\n","    'YS (MPa)': round(column_averages['YS (MPa)'], 0),\n","    'UTS (MPa)': round(column_averages['UTS (MPa)'], 0),\n","    'Hardness (HV)': round(column_averages['Hardness (HV)'], 0),\n","    'Dislocation Density (m⁻²)': round(column_averages['Dislocation Density (m⁻²)'], 2),\n","    'Strain Hardening Exponent (n)': round(column_averages['Strain Hardening Exponent (n)'], 2),\n","    'Strain Hardening Coefficient (K, MPa)': round(column_averages['Strain Hardening Coefficient (K, MPa)'], 0),\n","    'Grain Size (µm)': round(column_averages['Grain Size (µm)'], 1),\n","    'Elongation (%)': round(column_averages['Elongation (%)'], 1)\n","}\n","\n","# Replace missing values with rounded averages\n","for column, average in rounded_averages.items():\n","    data[column].fillna(average, inplace=True)\n","\n","# Generate the cleaned file name\n","cleaned_file_name = f\"{file_name.split('.')[0]}_cleaned.csv\"\n","\n","# Save the cleaned DataFrame to a new CSV file\n","data.to_csv(cleaned_file_name, index=False)\n","\n","# Download the cleaned CSV file\n","files.download(cleaned_file_name)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":831},"id":"w7dOB3RaMen3","executionInfo":{"status":"error","timestamp":1744583938698,"user_tz":-330,"elapsed":12696,"user":{"displayName":"Samridhi","userId":"09467702319846269570"}},"outputId":"43d43c68-dadf-4e2a-b085-131d1b811c5f"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-39f304b6-72bf-46ef-b517-cd739726fea8\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-39f304b6-72bf-46ef-b517-cd739726fea8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Raw_Data_Claude.csv to Raw_Data_Claude.csv\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-3bbc8751debf>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data['Test Temp (°C)'].fillna(25, inplace=True)\n","<ipython-input-18-3bbc8751debf>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data['Phases'].fillna('Austenite + Ferrite', inplace=True)\n","<ipython-input-18-3bbc8751debf>:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data['Strain Rate (s⁻¹)'].fillna(0.001, inplace=True)\n"]},{"output_type":"error","ename":"TypeError","evalue":"Could not convert string '580610565590600595575605560585590615555595600570590605580590-595565585620575600570590585550625595580545595630560598557618582603548602568588540635572592553608585598558600566593578' to numeric","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-3bbc8751debf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mcolumn_averages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns_to_average\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mcolumn_averages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Round the averages as specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6547\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6548\u001b[0m     ):\n\u001b[0;32m-> 6549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6551\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"median\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12418\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12419\u001b[0m     ) -> Series | float:\n\u001b[0;32m> 12420\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  12421\u001b[0m             \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12422\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12375\u001b[0m         \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skipna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_allowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 12377\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  12378\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12379\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6455\u001b[0m                     \u001b[0;34m\"with non-numeric dtypes.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6456\u001b[0m                 )\n\u001b[0;32m-> 6457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6459\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"any\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m             \u001b[0;31m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not convert string '{x}' to numeric\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1702\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Could not convert string '580610565590600595575605560585590615555595600570590605580590-595565585620575600570590585550625595580545595630560598557618582603548602568588540635572592553608585598558600566593578' to numeric"]}]},{"cell_type":"markdown","source":["# Code for **mean, median, std deviation, min** and **max** for all numeric fields"],"metadata":{"id":"mPI8eH-mmEMl"}},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import files\n","\n","# Define the file names\n","file_names = [\n","    'Raw_Data_ChatGPT_cleaned.csv',\n","    'Raw_Data_Claude_cleaned.csv',\n","    'Raw_Data_Gemini_cleaned.csv',\n","    'Raw_Data_Perplexity_cleaned.csv'\n","]\n","\n","# Loop through each file\n","for file_name in file_names:\n","    try:\n","        # Load the cleaned data file\n","        data = pd.read_csv(file_name)\n","\n","        # Select numeric fields\n","        numeric_data = data.select_dtypes(include=['float64', 'int64'])\n","\n","        # Calculate statistics\n","        statistics = {\n","            'mean': numeric_data.mean(),\n","            'median': numeric_data.median(),\n","            'std_dev': numeric_data.std(),\n","            'min': numeric_data.min(),\n","            'max': numeric_data.max()\n","        }\n","\n","        # Convert statistics to a DataFrame for better readability\n","        stats_df = pd.DataFrame(statistics)\n","\n","        # Display the statistics for the current file\n","        print(f\"Statistics for {file_name}:\")\n","        print(stats_df)\n","        print(\"\\n\")\n","\n","    except FileNotFoundError:\n","        print(f\"File {file_name} not found.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"2Dbjh0Yilopk","executionInfo":{"status":"ok","timestamp":1744571937221,"user_tz":-330,"elapsed":79,"user":{"displayName":"Samridhi","userId":"09467702319846269570"}},"outputId":"ca8c6e25-ac0c-4162-f231-0d945d06d931"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Statistics for Raw_Data_ChatGPT_cleaned.csv:\n","                                               mean        median  \\\n","Test Temp (°C)                         1.933333e+02  2.000000e+02   \n","Grain Size (µm)                        8.768333e+00  8.750000e+00   \n","Dislocation Density (m⁻²)              1.156604e+14  1.156604e+14   \n","YS (MPa)                               4.650000e+02  4.680000e+02   \n","UTS (MPa)                              7.202167e+02  7.200000e+02   \n","Hardness (HV)                          2.848500e+02  2.850000e+02   \n","Elongation (%)                         2.117667e+01  2.130000e+01   \n","Strain Rate (s⁻¹)                      7.666667e-04  1.000000e-03   \n","Strain Hardening Exponent (n)          2.058333e-01  2.100000e-01   \n","Strain Hardening Coefficient (K, MPa)  1.101217e+03  1.101000e+03   \n","\n","                                            std_dev           min  \\\n","Test Temp (°C)                         1.145058e+02  2.500000e+01   \n","Grain Size (µm)                        1.569896e+00  6.200000e+00   \n","Dislocation Density (m⁻²)              1.287744e+13  9.400000e+13   \n","YS (MPa)                               3.073561e+01  4.050000e+02   \n","UTS (MPa)                              3.928345e+01  6.500000e+02   \n","Hardness (HV)                          1.174564e+01  2.630000e+02   \n","Elongation (%)                         2.740120e+00  1.620000e+01   \n","Strain Rate (s⁻¹)                      2.515489e-04  5.000000e-04   \n","Strain Hardening Exponent (n)          2.579526e-02  1.600000e-01   \n","Strain Hardening Coefficient (K, MPa)  5.962171e+01  1.002000e+03   \n","\n","                                                max  \n","Test Temp (°C)                         3.500000e+02  \n","Grain Size (µm)                        1.200000e+01  \n","Dislocation Density (m⁻²)              1.400000e+14  \n","YS (MPa)                               5.190000e+02  \n","UTS (MPa)                              7.800000e+02  \n","Hardness (HV)                          3.070000e+02  \n","Elongation (%)                         2.580000e+01  \n","Strain Rate (s⁻¹)                      1.000000e-03  \n","Strain Hardening Exponent (n)          2.500000e-01  \n","Strain Hardening Coefficient (K, MPa)  1.199000e+03  \n","\n","\n","Statistics for Raw_Data_Claude_cleaned.csv:\n","                                               mean        median  \\\n","Test Temp (°C)                         2.330000e+01  2.300000e+01   \n","Grain Size (µm)                        1.464333e+01  1.430000e+01   \n","Dislocation Density (m⁻²)              5.218182e+14  5.200000e+14   \n","YS (MPa)                               5.858000e+02  5.890000e+02   \n","UTS (MPa)                              7.973667e+02  8.000000e+02   \n","Hardness (HV)                          2.830167e+02  2.850000e+02   \n","Elongation (%)                         2.593167e+01  2.600000e+01   \n","Strain Rate (s⁻¹)                      2.200000e-03  1.000000e-03   \n","Strain Hardening Exponent (n)          2.743333e-01  2.700000e-01   \n","Strain Hardening Coefficient (K, MPa)  1.057783e+03  1.059000e+03   \n","\n","                                            std_dev           min  \\\n","Test Temp (°C)                         3.115299e+00  1.700000e+01   \n","Grain Size (µm)                        3.856598e+00  6.000000e+00   \n","Dislocation Density (m⁻²)              6.167413e+13  4.200000e+14   \n","YS (MPa)                               2.145614e+01  5.400000e+02   \n","UTS (MPa)                              1.983147e+01  7.550000e+02   \n","Hardness (HV)                          1.171337e+01  2.580000e+02   \n","Elongation (%)                         2.857431e+00  1.900000e+01   \n","Strain Rate (s⁻¹)                      3.085230e-03  1.000000e-03   \n","Strain Hardening Exponent (n)          2.513467e-02  2.100000e-01   \n","Strain Hardening Coefficient (K, MPa)  3.350896e+01  9.950000e+02   \n","\n","                                                max  \n","Test Temp (°C)                         3.100000e+01  \n","Grain Size (µm)                        2.300000e+01  \n","Dislocation Density (m⁻²)              6.700000e+14  \n","YS (MPa)                               6.350000e+02  \n","UTS (MPa)                              8.450000e+02  \n","Hardness (HV)                          3.120000e+02  \n","Elongation (%)                         3.300000e+01  \n","Strain Rate (s⁻¹)                      1.000000e-02  \n","Strain Hardening Exponent (n)          3.400000e-01  \n","Strain Hardening Coefficient (K, MPa)  1.130000e+03  \n","\n","\n","Statistics for Raw_Data_Gemini_cleaned.csv:\n","                                               mean        median  \\\n","Test Temp (°C)                         3.650000e+01  2.500000e+01   \n","Grain Size (µm)                        2.349833e+01  1.975000e+01   \n","Dislocation Density (m⁻²)              3.147800e+13  2.400000e+13   \n","YS (MPa)                               3.817333e+02  4.075000e+02   \n","UTS (MPa)                              5.939000e+02  6.075000e+02   \n","Hardness (HV)                          1.910600e+02  1.900000e+02   \n","Elongation (%)                         2.838500e+01  2.810000e+01   \n","Strain Rate (s⁻¹)                      1.958333e-03  1.000000e-03   \n","Strain Hardening Exponent (n)          2.175000e-01  2.200000e-01   \n","Strain Hardening Coefficient (K, MPa)  7.932750e+02  8.000000e+02   \n","\n","                                            std_dev           min  \\\n","Test Temp (°C)                         4.415209e+01 -7.500000e+01   \n","Grain Size (µm)                        9.999381e+00  1.000000e+01   \n","Dislocation Density (m⁻²)              2.909076e+13  1.500000e+12   \n","YS (MPa)                               8.662629e+01  2.650000e+02   \n","UTS (MPa)                              1.226425e+02  4.350000e+02   \n","Hardness (HV)                          3.659938e+01  1.420000e+02   \n","Elongation (%)                         6.803808e+00  1.500000e+01   \n","Strain Rate (s⁻¹)                      2.077595e-03  5.000000e-04   \n","Strain Hardening Exponent (n)          3.279805e-02  1.500000e-01   \n","Strain Hardening Coefficient (K, MPa)  1.758933e+02  5.700000e+02   \n","\n","                                                max  \n","Test Temp (°C)                         1.500000e+02  \n","Grain Size (µm)                        4.200000e+01  \n","Dislocation Density (m⁻²)              1.000000e+14  \n","YS (MPa)                               5.100000e+02  \n","UTS (MPa)                              7.600000e+02  \n","Hardness (HV)                          2.500000e+02  \n","Elongation (%)                         4.100000e+01  \n","Strain Rate (s⁻¹)                      1.000000e-02  \n","Strain Hardening Exponent (n)          2.800000e-01  \n","Strain Hardening Coefficient (K, MPa)  1.030000e+03  \n","\n","\n","Statistics for Raw_Data_Perplexity_cleaned.csv:\n","                                               mean        median  \\\n","Test Temp (°C)                         3.862500e+02  4.000000e+02   \n","Grain Size (µm)                        5.467500e+00  4.990000e+00   \n","Dislocation Density (m⁻²)              4.532533e+14  3.940000e+14   \n","YS (MPa)                               5.127743e+02  5.185000e+02   \n","UTS (MPa)                              7.050620e+02  7.060450e+02   \n","Hardness (HV)                          2.492668e+02  2.507250e+02   \n","Elongation (%)                         1.816867e+01  1.718000e+01   \n","Strain Rate (s⁻¹)                      5.284833e-02  6.125000e-02   \n","Strain Hardening Exponent (n)          2.955000e-01  2.900000e-01   \n","Strain Hardening Coefficient (K, MPa)  7.441482e+02  7.604150e+02   \n","\n","                                            std_dev           min  \\\n","Test Temp (°C)                         1.936724e+02  2.500000e+01   \n","Grain Size (µm)                        3.444988e+00  1.200000e+00   \n","Dislocation Density (m⁻²)              2.642550e+14  1.200000e+13   \n","YS (MPa)                               5.662347e+01  4.042000e+02   \n","UTS (MPa)                              5.740704e+01  6.121100e+02   \n","Hardness (HV)                          2.914457e+01  2.012400e+02   \n","Elongation (%)                         5.868843e+00  1.006000e+01   \n","Strain Rate (s⁻¹)                      2.993544e-02  1.500000e-03   \n","Strain Hardening Exponent (n)          1.195532e-01  1.100000e-01   \n","Strain Hardening Coefficient (K, MPa)  1.484952e+02  5.053800e+02   \n","\n","                                                max  \n","Test Temp (°C)                         6.000000e+02  \n","Grain Size (µm)                        2.223000e+01  \n","Dislocation Density (m⁻²)              9.260000e+14  \n","YS (MPa)                               5.971400e+02  \n","UTS (MPa)                              7.994300e+02  \n","Hardness (HV)                          2.998000e+02  \n","Elongation (%)                         2.969000e+01  \n","Strain Rate (s⁻¹)                      9.920000e-02  \n","Strain Hardening Exponent (n)          4.900000e-01  \n","Strain Hardening Coefficient (K, MPa)  9.957600e+02  \n","\n","\n"]}]},{"cell_type":"markdown","source":["# Visualisation Using **Differnt Plots**"],"metadata":{"id":"rPz76YL4mcAo"}},{"cell_type":"markdown","source":["Pair Plot"],"metadata":{"id":"EFIDUGCSoaev"}},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Define the file names\n","file_names = [\n","    'Raw_Data_ChatGPT_cleaned.csv',\n","    'Raw_Data_Claude_cleaned.csv',\n","    'Raw_Data_Gemini_cleaned.csv',\n","    'Raw_Data_Perplexity_cleaned.csv'\n","]\n","\n","# Loop through each file to create pair plots\n","for file_name in file_names:\n","    try:\n","        # Load the cleaned data file\n","        data = pd.read_csv(file_name)\n","\n","        # Select numeric fields for the pair plot\n","        numeric_data = data.select_dtypes(include=['float64', 'int64'])\n","\n","        # Create a pair plot\n","        sns.set(style=\"whitegrid\")\n","        pair_plot = sns.pairplot(numeric_data, diag_kind=\"hist\", height=2.5, aspect=1)\n","\n","        # Set title for the plot\n","        plt.suptitle(f\"Pair Plot of Key Properties for {file_name}\", y=1.02, fontsize=16)\n","\n","        # Save the plot as an image file\n","        plot_file_name = f\"{file_name.split('.')[0]}_pairplot.png\"\n","        plt.savefig(plot_file_name, bbox_inches='tight')\n","\n","        # Show the plot\n","        plt.show()\n","\n","        print(f\"Pair plot saved as {plot_file_name}.\")\n","\n","    except FileNotFoundError:\n","        print(f\"File {file_name} not found.\")\n"],"metadata":{"id":"1cyjdzfsma3i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comparision Plot between differnet properties"],"metadata":{"id":"iN73rhxMojh5"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Define the file names\n","file_names = [\n","    'Raw_Data_ChatGPT_cleaned.csv',\n","    'Raw_Data_Claude_cleaned.csv',\n","    'Raw_Data_Gemini_cleaned.csv',\n","    'Raw_Data_Perplexity_cleaned.csv'\n","]\n","\n","# Define the X vs Y combinations for plotting\n","plots = [\n","    ('Strain Rate (s⁻¹)', 'Grain Size (µm)'),\n","    ('Grain Size (µm)', 'YS (MPa)'),\n","    ('Grain Size (µm)', 'Elongation (%)'),\n","    ('Hardness (HV)', 'Grain Size (µm)')\n","]\n","\n","# Loop through each file\n","for file_name in file_names:\n","    try:\n","        # Load the cleaned data file\n","        data = pd.read_csv(file_name)\n","\n","        # Loop through each X vs Y combination\n","        for x, y in plots:\n","            # Create a sorted copy of the data\n","            data_sorted = data.copy()\n","            data_sorted.sort_values(by=x, inplace=True)\n","\n","            plt.figure(figsize=(8, 6))\n","            sns.lineplot(data=data_sorted, x=x, y=y)\n","            plt.title(f'{x} vs {y} for {file_name.split(\".\")[0]}', fontsize=14)\n","            plt.xlabel(x, fontsize=12)\n","            plt.ylabel(y, fontsize=12)\n","            plt.grid(True)\n","            plt.tight_layout()\n","\n","            # Save each plot as an image file\n","            plot_file_name = f\"{file_name.split('.')[0]}_{x.replace(' ', '_').replace('/', '_')}_vs_{y.replace(' ', '_').replace('/', '_')}.png\"\n","            plt.savefig(plot_file_name)\n","\n","            # Display the plot\n","            plt.show()\n","\n","        print(f\"Plots for {file_name} saved successfully!\")\n","\n","    except FileNotFoundError:\n","        print(f\"File {file_name} not found.\")\n"],"metadata":{"id":"Upa6zRIfVNQ4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Heatmap Plot Code"],"metadata":{"id":"NzroRW57IuqF"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np # Import numpy and assign it to the alias 'np'\n","\n","# Load the datasets\n","file_names = [\n","    'Raw_Data_ChatGPT_cleaned.csv',\n","    'Raw_Data_Claude_cleaned.csv',\n","    'Raw_Data_Gemini_cleaned.csv',\n","    'Raw_Data_Perplexity_cleaned.csv'\n","]\n","\n","dataframes = [pd.read_csv(file_name) for file_name in file_names]\n","\n","# Example for comparing mean values of 'YS (MPa)'\n","ys_means = [df['YS (MPa)'].mean() for df in dataframes]\n","print(\"Mean YS (MPa) for each dataset:\", ys_means)\n","\n","# Example for comparing correlation matrices\n","for i, df in enumerate(dataframes):\n","    # Select only numeric columns for correlation calculation\n","    numeric_df = df.select_dtypes(include=['number'])\n","    corr_matrix = numeric_df.corr()\n","    print(f\"Correlation Matrix for Dataset {i + 1}:\")\n","    print(corr_matrix)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n","    plt.title(f\"Correlation Matrix for Dataset {i + 1}\")\n","    plt.show()\n","\n","# Stack correlation matrices\n","# Select only numeric columns for correlation calculation\n","corr_matrices = [df.select_dtypes(include=['number']).corr().values for df in dataframes]\n","stacked_corr = np.stack(corr_matrices) # Use np.stack\n","\n","\n","# Calculate average correlation matrix\n","avg_corr_matrix = np.mean(stacked_corr, axis=0)\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(avg_corr_matrix, annot=True, cmap='coolwarm')\n","plt.title(\"Average Correlation Across Datasets\")\n","plt.show()\n","\n","# Example for creating a summary table\n","summary_table = []\n","for df in dataframes:\n","    summary_row = {\n","        'Dataset': df.columns[0],\n","        'Mean YS (MPa)': df['YS (MPa)'].mean(),\n","        'Median YS (MPa)': df['YS (MPa)'].median(),\n","        'Std YS (MPa)': df['YS (MPa)'].std()\n","    }\n","    summary_table.append(summary_row)\n","\n","summary_df = pd.DataFrame(summary_table)\n","print(summary_df)\n"],"metadata":{"id":"1fm023QFNjSJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comparision between Original and AI generated data"],"metadata":{"id":"uWo3fwLzQaOT"}},{"cell_type":"code","source":["# Step 1: Import required libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","\n","# Load the datasets\n","file_names = [\n","    'Raw_Data_ChatGPT_cleaned.csv',\n","    'Raw_Data_Claude_cleaned.csv',\n","    'Raw_Data_Gemini_cleaned.csv',\n","    'Raw_Data_Perplexity_cleaned.csv'\n","]\n","\n","dataframes = [pd.read_csv(file_name) for file_name in file_names]\n","\n","# Step 3: Load the uploaded CSVs\n","df_chatgpt = pd.read_csv('Raw_Data_ChatGPT_cleaned.csv')\n","df_claude = pd.read_csv('Raw_Data_Claude_cleaned.csv')\n","df_gemini = pd.read_csv('Raw_Data_Gemini_cleaned.csv')\n","df_perplexity = pd.read_csv('Raw_Data_Perplexity_cleaned.csv')\n","df_manual = pd.read_csv('ManualData.csv')  # Make sure your manual data is named exactly this\n","\n","# Step 4: Define common properties to compare\n","properties = ['YS (MPa)', 'UTS (MPa)', 'Hardness (HV)', 'Elongation (%)', 'Strain Rate (s⁻¹)']\n","\n","# Step 5: Create subplots for each property\n","plt.figure(figsize=(18, 10))\n","\n","for i, prop in enumerate(properties, 1):\n","    plt.subplot(2, 3, i)\n","\n","    plt.plot(df_manual[prop], label='Manual', marker='o')\n","    plt.plot(df_chatgpt[prop], label='ChatGPT', marker='x')\n","    plt.plot(df_claude[prop], label='Claude', marker='s')\n","    plt.plot(df_gemini[prop], label='Gemini', marker='^')\n","    plt.plot(df_perplexity[prop], label='Perplexity', marker='*')\n","\n","    plt.title(prop)\n","    plt.xlabel('Sample Index')\n","    plt.ylabel(prop)\n","    plt.grid(True)\n","    plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"7rt5SuixQ2_f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comparision between **mean, median, std, min, max** of Original and AI generated Data"],"metadata":{"id":"p3edGvSwWfXy"}},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import files\n","\n","# Load the datasets\n","file_names = [\n","    'Raw_Data_ChatGPT_cleaned.csv',\n","    'Raw_Data_Claude_cleaned.csv',\n","    'Raw_Data_Gemini_cleaned.csv',\n","    'Raw_Data_Perplexity_cleaned.csv'\n","]\n","\n","dataframes = [pd.read_csv(file_name) for file_name in file_names]\n","\n","\n","# Load datasets\n","df_chatgpt = pd.read_csv('Raw_Data_ChatGPT_cleaned.csv')\n","df_claude = pd.read_csv('Raw_Data_Claude_cleaned.csv')\n","df_gemini = pd.read_csv('Raw_Data_Gemini_cleaned.csv')\n","df_perplexity = pd.read_csv('Raw_Data_Perplexity_cleaned.csv')\n","df_manual = pd.read_csv('ManualData.csv')\n","\n","# Define properties to analyze\n","properties = ['YS (MPa)', 'UTS (MPa)', 'Hardness (HV)', 'Elongation (%)', 'Strain Rate (s⁻¹)']\n","datasets = {\n","    'Manual': df_manual,\n","    'ChatGPT': df_chatgpt,\n","    'Claude': df_claude,\n","    'Gemini': df_gemini,\n","    'Perplexity': df_perplexity\n","}\n","\n","# Calculate and store stats\n","stats_to_plot = ['mean', 'median', 'std', 'min', 'max']\n","stat_results = {stat: pd.DataFrame(columns=datasets.keys(), index=properties) for stat in stats_to_plot}\n","\n","for name, df in datasets.items():\n","    for prop in properties:\n","        # Convert to numeric, handling errors\n","        try:\n","            df[prop] = pd.to_numeric(df[prop], errors='coerce')\n","        except ValueError:\n","            print(f\"Warning: Non-numeric data found in column '{prop}' of dataset '{name}'. Replacing with NaN.\")\n","            df[prop] = pd.to_numeric(df[prop], errors='coerce')  # Force conversion to numeric, invalid values become NaN\n","\n","        stat_results['mean'].loc[prop, name] = df[prop].mean()\n","        stat_results['median'].loc[prop, name] = df[prop].median()\n","        stat_results['std'].loc[prop, name] = df[prop].std()\n","        stat_results['min'].loc[prop, name] = df[prop].min()\n","        stat_results['max'].loc[prop, name] = df[prop].max()\n","\n","# ... (rest of your code) ...\n","# Plotting\n","plt.figure(figsize=(20, 20))\n","for i, stat in enumerate(stats_to_plot, 1):\n","    plt.subplot(3, 2, i)\n","    stat_results[stat].astype(float).plot(kind='bar', ax=plt.gca())\n","    plt.title(f'{stat.capitalize()} Comparison')\n","    plt.ylabel(stat.capitalize())\n","    plt.xticks(rotation=45)\n","    plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"mdcvi7mtRzYi"},"execution_count":null,"outputs":[]}]}